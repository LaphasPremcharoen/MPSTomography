{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Fidelity of Iterative Projection vs. Initial State Complexity and Qubit Count\n",
    "\n",
    "## Overview\n",
    "This notebook investigates how the fidelity between an initial quantum state and the state resulting from an iterative projection process changes with:\n",
    "1. The complexity (ansatz depth) of the initial state.\n",
    "2. The total number of qubits in the system.\n",
    "\n",
    "The process for each run is:\n",
    "1. Generate an initial N-qubit quantum state, `|psi_initial>`, using a `RealAmplitudes` ansatz with a specific `PSI_ANSATZ_DEPTH` and `NUM_QUBITS_EXP`.\n",
    "2. Optimize rank-1 projectors `P_ij*` for each nearest-neighbor pair to minimize `<psi_initial|P_ij*|psi_initial>`.\n",
    "3. Sequentially apply filter operators `(I - P_ij*)` to `|psi_initial>` and renormalize, producing `|psi_final>`.\n",
    "4. Calculate the fidelity $F(|\\psi_{initial}\\rangle, |\\psi_{final}\\rangle)$.\n",
    "\n",
    "This is repeated for several random instances at each `PSI_ANSATZ_DEPTH` and for each `NUM_QUBITS_EXP`. The average fidelity for each depth and qubit count is then plotted, with separate lines for each qubit count showing fidelity vs. ansatz depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "- `numpy`\n",
    "- `qiskit`\n",
    "- `scipy`\n",
    "- `matplotlib` (for plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import RealAmplitudes, TwoLocal\n",
    "from qiskit.quantum_info import Statevector, Operator, SparsePauliOp, state_fidelity\n",
    "from qiskit.visualization import circuit_drawer\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "import time # To time the experiment\n",
    "\n",
    "try:\n",
    "    from scipy.optimize import minimize\n",
    "except ModuleNotFoundError:\n",
    "    print(\"ERROR: scipy is not installed. Please install it: pip install scipy\")\n",
    "    def minimize(*args, **kwargs):\n",
    "        raise RuntimeError(\"scipy.optimize.minimize not found. Please install scipy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment Configuration ---\n",
    "QUBIT_COUNTS_EXP = [3, 4, 5, 6, 7, 8] # List of qubit numbers to test\n",
    "MAX_PSI_ANSATZ_DEPTH = 8             # Max depth for RealAmplitudes (0 to MAX_PSI_ANSATZ_DEPTH)\n",
    "NUM_RUNS_PER_CONFIG = 3            # Number of random instances per (qubit_count, depth) for averaging\n",
    "\n",
    "# --- Fixed Parameters from previous setup (can be tuned) ---\n",
    "PROJECTOR_U_REPS = 1       # Repetitions in TwoLocal for U(theta)\n",
    "SCIPY_COBYLA_MAXITER = 1500  # Max iterations for COBYLA (reduced for broader experiment)\n",
    "SCIPY_COBYLA_TOL = 1e-4      # Tolerance for COBYLA (adjusted for speed)\n",
    "MAIN_SEED = 42               # Main seed for reproducibility of the entire experiment\n",
    "\n",
    "# Set NumPy's random seed. This will be reset for each run for comparable randomness.\n",
    "np.random.seed(MAIN_SEED)\n",
    "print(f\"Main NumPy random seed for experiment: {MAIN_SEED}\")\n",
    "\n",
    "VISUALIZE_CIRCUITS = False # Set to True to draw circuits (can be very verbose)\n",
    "VERBOSE_OPTIMIZATION = False # Set to True for detailed optimizer output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core Logic Function\n",
    "This function encapsulates the process for a single experimental run (one qubit count, one depth, one random seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_projection_experiment(num_qubits, psi_depth, run_seed):\n",
    "    \"\"\"Runs one instance of the state generation, projector optimization, \n",
    "    and iterative filtering, returning the final fidelity.\"\"\"\n",
    "    np.random.seed(run_seed) # Set seed for this specific run\n",
    "\n",
    "    # --- Step 1: Create initial quantum state |psi_initial> ---\n",
    "    psi_ansatz = RealAmplitudes(num_qubits, reps=psi_depth, entanglement='linear')\n",
    "    num_psi_params = psi_ansatz.num_parameters\n",
    "    # Ensure parameters are generated even if num_psi_params is 0 (for depth 0)\n",
    "    if num_psi_params > 0:\n",
    "        random_psi_params = np.random.rand(num_psi_params) * 2 * np.pi\n",
    "        psi_circuit = psi_ansatz.assign_parameters(random_psi_params)\n",
    "    else: # Depth 0 means no parameters, just the |0...0> state implicitly\n",
    "        psi_circuit = QuantumCircuit(num_qubits) # Effectively |0...0>\n",
    "\n",
    "    # Visualization (optional and conditional)\n",
    "    # if VISUALIZE_CIRCUITS and psi_depth > 0: ... \n",
    "\n",
    "    try:\n",
    "        psi_initial_vector = Statevector(psi_circuit)\n",
    "    except Exception as e:\n",
    "        # print(f\"    ERROR (Run {run_seed}, Depth {psi_depth}, Qubits {num_qubits}): Could not create Statevector: {e}\")\n",
    "        return np.nan # Return NaN on failure\n",
    "\n",
    "    # --- Step 2: Define base projectors and U(theta) ansatz ---\n",
    "    proj_00_on_qubits_static_pauli_sum = {}\n",
    "    if num_qubits > 1: # Projectors only make sense for > 1 qubit\n",
    "        for q1_idx in range(num_qubits - 1):\n",
    "            q2_idx = q1_idx + 1\n",
    "            pauli_list = [\n",
    "                (\"I\" * num_qubits, 0.25),\n",
    "                (\"\".join(['Z' if i == q1_idx else 'I' for i in range(num_qubits)]), 0.25),\n",
    "                (\"\".join(['Z' if i == q2_idx else 'I' for i in range(num_qubits)]), 0.25),\n",
    "                (\"\".join(['Z' if i == q1_idx or i == q2_idx else 'I' for i in range(num_qubits)]), 0.25)\n",
    "            ]\n",
    "            reversed_pauli_list = [(p_str[::-1], coeff) for p_str, coeff in pauli_list]\n",
    "            proj_00_on_qubits_static_pauli_sum[(q1_idx, q2_idx)] = SparsePauliOp.from_list(reversed_pauli_list)\n",
    "\n",
    "    u_ansatz_2q = TwoLocal(2, rotation_blocks=['ry', 'rz'], entanglement_blocks='cx',\n",
    "                           reps=PROJECTOR_U_REPS, entanglement='linear')\n",
    "    num_u_params = u_ansatz_2q.num_parameters\n",
    "\n",
    "    # --- Step 3: Optimize projectors ---\n",
    "    optimized_projectors_P_star = []\n",
    "    if num_qubits > 1:\n",
    "        qubit_pairs = [(i, i + 1) for i in range(num_qubits - 1)]\n",
    "        for q1, q2 in qubit_pairs:\n",
    "            base_proj_spo = proj_00_on_qubits_static_pauli_sum[(q1, q2)]\n",
    "            def cost_func(params):\n",
    "                try:\n",
    "                    u_circ_2q = u_ansatz_2q.assign_parameters(params)\n",
    "                    u_full_qc_ = QuantumCircuit(num_qubits)\n",
    "                    u_full_qc_.compose(u_circ_2q, qubits=[q1, q2], inplace=True)\n",
    "                    u_op = Operator(u_full_qc_)\n",
    "                    p_op_obj = u_op @ base_proj_spo @ u_op.adjoint()\n",
    "                    return np.real(psi_initial_vector.expectation_value(p_op_obj))\n",
    "                except Exception:\n",
    "                    return np.nan \n",
    "            \n",
    "            init_params = np.random.rand(num_u_params) * 2 * np.pi\n",
    "            try:\n",
    "                opt_res = minimize(fun=cost_func, x0=init_params, method='COBYLA',\n",
    "                                   tol=SCIPY_COBYLA_TOL, \n",
    "                                   options={'maxiter': SCIPY_COBYLA_MAXITER, 'disp': VERBOSE_OPTIMIZATION})\n",
    "                if opt_res.success or (not np.isnan(opt_res.fun) and opt_res.fun < 1.0): # Accept if fun is reasonable\n",
    "                    u_circ_2q_opt_ = u_ansatz_2q.assign_parameters(opt_res.x)\n",
    "                    u_full_qc_opt_ = QuantumCircuit(num_qubits)\n",
    "                    u_full_qc_opt_.compose(u_circ_2q_opt_, qubits=[q1, q2], inplace=True)\n",
    "                    u_op_opt_ = Operator(u_full_qc_opt_)\n",
    "                    p_star_obj = u_op_opt_ @ base_proj_spo @ u_op_opt_.adjoint()\n",
    "                    optimized_projectors_P_star.append({'qubits': (q1,q2), 'P_star_op': p_star_obj})\n",
    "            except Exception:\n",
    "                pass \n",
    "\n",
    "    # --- Step 4: Iterative projection ---\n",
    "    if not optimized_projectors_P_star and num_qubits > 1:\n",
    "        # If optimization failed for all projectors but there were pairs to optimize\n",
    "        # this run might not be very informative, could return NaN or treat as fidelity 1\n",
    "        # For now, assume if no projectors, state doesn't change.\n",
    "        pass \n",
    "        \n",
    "    current_psi = psi_initial_vector.copy()\n",
    "    if num_qubits > 0 : # Identity op only if there are qubits\n",
    "        id_op = Operator(np.eye(2**num_qubits, dtype=complex))\n",
    "    else: # Should not happen with QUBIT_COUNTS_EXP setting\n",
    "        return 1.0 \n",
    "\n",
    "    for p_info in optimized_projectors_P_star:\n",
    "        k_op = id_op - p_info['P_star_op']\n",
    "        proj_psi_unnorm = current_psi.evolve(k_op)\n",
    "        norm = np.linalg.norm(proj_psi_unnorm.data)\n",
    "        if norm < 1e-9:\n",
    "            current_psi = Statevector(proj_psi_unnorm.data, dims=proj_psi_unnorm.dims())\n",
    "            break\n",
    "        current_psi = Statevector(proj_psi_unnorm.data / norm, dims=proj_psi_unnorm.dims())\n",
    "    \n",
    "    final_psi = current_psi\n",
    "\n",
    "    # --- Step 5: Calculate Fidelity ---\n",
    "    final_norm = np.linalg.norm(final_psi.data)\n",
    "    if final_norm < 1e-9:\n",
    "        return 0.0 \n",
    "    if abs(final_norm - 1.0) > 1e-7:\n",
    "        final_psi = Statevector(final_psi.data / final_norm, dims=final_psi.dims())\n",
    "        \n",
    "    init_norm = np.linalg.norm(psi_initial_vector.data)\n",
    "    if abs(init_norm - 1.0) > 1e-7:\n",
    "        # This shouldn't happen if Statevector(circuit) works correctly\n",
    "        psi_initial_vector = Statevector(psi_initial_vector.data / init_norm, dims=psi_initial_vector.dims())\n",
    "        \n",
    "    return state_fidelity(psi_initial_vector, final_psi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running the Experiment\n",
    "Outer loop iterates through `QUBIT_COUNTS_EXP`. Inner loop iterates through `PSI_ANSATZ_DEPTH`. For each configuration, `NUM_RUNS_PER_CONFIG` are performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_values = list(range(MAX_PSI_ANSATZ_DEPTH + 1))\n",
    "results_by_qubit_count = {} # Store {num_qubits: {'avg_fidelities': [], 'std_fidelities': []}}\n",
    "\n",
    "overall_experiment_start_time = time.time()\n",
    "\n",
    "for n_qubits in QUBIT_COUNTS_EXP:\n",
    "    print(f\"\\n===== Processing for NUM_QUBITS_EXP = {n_qubits} =====\")\n",
    "    current_qubit_avg_fidelities = []\n",
    "    current_qubit_std_fidelities = []\n",
    "    \n",
    "    for depth in depth_values:\n",
    "        print(f\"  Processing PSI_ANSATZ_DEPTH = {depth} for {n_qubits} qubits...\")\n",
    "        current_config_fidelities = []\n",
    "        config_start_time = time.time()\n",
    "        \n",
    "        for i_run in range(NUM_RUNS_PER_CONFIG):\n",
    "            run_specific_seed = MAIN_SEED + n_qubits * 100 + depth * 10 + i_run # Ensure unique seeds\n",
    "            # print(f\"    Run {i_run + 1}/{NUM_RUNS_PER_CONFIG} (Seed: {run_specific_seed})...\") # Verbose\n",
    "            \n",
    "            fidelity = run_single_projection_experiment(n_qubits, depth, run_specific_seed)\n",
    "            \n",
    "            if not np.isnan(fidelity):\n",
    "                current_config_fidelities.append(fidelity)\n",
    "            # else: print(f\"      Run failed for seed {run_specific_seed}, fidelity is NaN.\") # Verbose\n",
    "                \n",
    "        config_end_time = time.time()\n",
    "        # print(f\"    Finished all runs for depth {depth} in {config_end_time - config_start_time:.2f}s\") # Verbose\n",
    "\n",
    "        if current_config_fidelities:\n",
    "            avg_fid = np.mean(current_config_fidelities)\n",
    "            std_fid = np.std(current_config_fidelities)\n",
    "            current_qubit_avg_fidelities.append(avg_fid)\n",
    "            current_qubit_std_fidelities.append(std_fid)\n",
    "            print(f\"    Avg Fidelity for {n_qubits} qubits, depth {depth}: {avg_fid:.4f} +/- {std_fid:.4f}\")\n",
    "        else:\n",
    "            current_qubit_avg_fidelities.append(np.nan)\n",
    "            current_qubit_std_fidelities.append(np.nan)\n",
    "            print(f\"    No successful runs for {n_qubits} qubits, depth {depth}. Avg Fidelity: NaN\")\n",
    "    \n",
    "    results_by_qubit_count[n_qubits] = {\n",
    "        'avg_fidelities': current_qubit_avg_fidelities,\n",
    "        'std_fidelities': current_qubit_std_fidelities\n",
    "    }\n",
    "    print(f\"  --- Finished processing for {n_qubits} qubits ---\")\n",
    "\n",
    "overall_experiment_end_time = time.time()\n",
    "print(f\"\\nTotal experiment time: {overall_experiment_end_time - overall_experiment_start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plotting Results\n",
    "Plot the average fidelity against the `PSI_ANSATZ_DEPTH` for each number of qubits, with distinct lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for n_qubits, results in results_by_qubit_count.items():\n",
    "    # Filter out NaN values for plotting if a whole (depth, qubit_count) config failed\n",
    "    valid_indices = ~np.isnan(results['avg_fidelities'])\n",
    "    plot_depths = np.array(depth_values)[valid_indices]\n",
    "    plot_avg_fidelities = np.array(results['avg_fidelities'])[valid_indices]\n",
    "    plot_std_fidelities = np.array(results['std_fidelities'])[valid_indices]\n",
    "    \n",
    "    if len(plot_depths) > 0: # Only plot if there's data\n",
    "        plt.errorbar(plot_depths, plot_avg_fidelities, yerr=plot_std_fidelities, \n",
    "                     marker='o', linestyle='-', capsize=3, label=f'{n_qubits} Qubits')\n",
    "\n",
    "plt.xlabel(\"Initial State Ansatz Depth (PSI_ANSATZ_DEPTH)\")\n",
    "plt.ylabel(\"Average Fidelity (F(|psi_initial>, |psi_final>))\")\n",
    "plt.title(f\"Avg Fidelity vs. State Complexity for Different Qubit Counts ({NUM_RUNS_PER_CONFIG} Runs/Config)\")\n",
    "plt.xticks(depth_values)\n",
    "plt.ylim(-0.05, 1.05) # Fidelity is between 0 and 1\n",
    "plt.grid(True, which='both', linestyle='--')\n",
    "plt.legend(title=\"Number of Qubits\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Execution Guidance & Expected Output\n",
    "\n",
    "1.  **Kernel:** Ensure a Python 3 kernel with `qiskit`, `numpy`, `scipy`, and `matplotlib`.\n",
    "2.  **Run All Cells:** Execute cells sequentially from top to bottom.\n",
    "3.  **Configuration (Cell 2):**\n",
    "    *   `QUBIT_COUNTS_EXP`: List of qubit numbers (e.g., `[3, 4, 5, 6, 7, 8]`).\n",
    "    *   `MAX_PSI_ANSATZ_DEPTH`: Max depth for the `RealAmplitudes` ansatz.\n",
    "    *   `NUM_RUNS_PER_CONFIG`: Number of random instances per (qubit count, depth) pair. Increase for smoother averages, decrease for faster runs.\n",
    "    *   `SCIPY_COBYLA_MAXITER`, `SCIPY_COBYLA_TOL`: Optimizer settings. These are critical for runtime. For an exploratory run, `MAXITER` might be lowered (e.g., 500-1500) and `TOL` increased (e.g., 1e-4) to speed things up, especially as the number of qubits increases.\n",
    "4.  **Patience:** This experiment will be **significantly more computationally intensive** than the single run due to the nested loops over qubit counts, ansatz depths, and random runs. The total number of optimizations is `len(QUBIT_COUNTS_EXP) * (MAX_PSI_ANSATZ_DEPTH + 1) * NUM_RUNS_PER_CONFIG * (avg_num_projectors_per_qubit_count)`.\n",
    "    *   For example, with `QUBIT_COUNTS_EXP = [3,4,5,6,7,8]` (6 settings), `MAX_PSI_ANSATZ_DEPTH = 8` (9 depths), `NUM_RUNS_PER_CONFIG = 3`, for 8 qubits (7 projectors): `6 * 9 * 3 * ~7` optimizations could be a rough lower bound for the 8-qubit case alone if all other qubit counts are fast. Consider reducing `NUM_RUNS_PER_CONFIG` to 1 or 2, or `MAX_PSI_ANSATZ_DEPTH` to a smaller value (e.g., 4 or 5) for initial tests.\n",
    "\n",
    "### Expected Output\n",
    "- Print statements showing the progress for each qubit count, depth, and run.\n",
    "- The average fidelity (and standard deviation) for each (qubit count, depth) configuration.\n",
    "- A final plot showing Average Fidelity on the Y-axis and Initial State Ansatz Depth on the X-axis, with distinct lines for each number of qubits tested."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}